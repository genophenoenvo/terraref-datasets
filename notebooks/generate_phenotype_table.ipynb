{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotype Table for Initial Set of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dataset downloaded from betydb in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/terraref-datasets/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (18,26,32,35) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_0 = pd.read_csv('../data/raw/mac_season_4.csv')\n",
    "# df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'checked', 'result_type', 'id', 'citation_id', 'site_id',\n",
       "       'treatment_id', 'sitename', 'city', 'lat', 'lon', 'scientificname',\n",
       "       'commonname', 'genus', 'species_id', 'cultivar_id', 'author',\n",
       "       'citation_year', 'treatment', 'date', 'time', 'raw_date', 'month',\n",
       "       'year', 'dateloc', 'trait', 'trait_description', 'mean', 'units', 'n',\n",
       "       'statname', 'stat', 'notes', 'access_level', 'cultivar', 'entity',\n",
       "       'method_name', 'view_url', 'edit_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_0.drop(labels=['Unnamed: 0', 'checked', 'citation_id', 'city', 'scientificname', 'commonname', 'genus',\n",
    "                        'species_id', 'author', 'citation_year', 'trait_description', 'units', 'n', 'statname',\n",
    "                        'stat', 'access_level', 'view_url', 'edit_url'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Range and Column Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['range'] = df_2['sitename'].str.extract(\"Range (\\d+)\").astype(int)\n",
    "df_2['column'] = df_2['sitename'].str.extract(\"Column (\\d+)\").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert table to wide format\n",
    "* Each trait should have its own column\n",
    "* Rename `mean` column to `value` for easier understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_2.rename({'mean': 'value'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "traits_to_keep = ['leaf_temperature', 'ambient_humidity', 'proximal_air_temperature', 'surface_temperature',\n",
    "                  'aboveground_dry_biomass', 'canopy_height', 'flag_leaf_emergence_time', 'flowering_time',\n",
    "                  'canopy_cover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = pd.DataFrame(data=df_3, index=df_3.index, columns=traits_to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = pd.concat([df_3, empty_df.reindex(df_3.index)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop more unecessary (at this time) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_4.drop(labels=['result_type', 'treatment_id', 'treatment', 'dateloc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Populate empty columns with available values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is very slow - needs refactoring for .py script and reproducible notebook \n",
    "\n",
    "run_slow_stuff = False\n",
    "\n",
    "if run_slow_stuff:\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for index, row in df_5.iterrows():            \n",
    "        if counter % 1000 == 0:\n",
    "            print(counter)            \n",
    "            counter += 1\n",
    "        for trait in traits_to_keep:\n",
    "            if row['trait'] == trait:                \n",
    "                df_5.loc[index, [trait]] = row['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Change plots to index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6 = df_5.set_index('sitename')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop some columns that are redundant or can be explained in data dictionary\n",
    "* `month`\n",
    "* `year`\n",
    "* `notes`\n",
    "* `trait` - now have trait values in wide format (one column per trait requested for this iteration of dataset)\n",
    "* `method_name`\n",
    "* `notes` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_6.drop(labels=['month', 'year', 'notes', 'trait', 'method_name', 'notes'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in `df_6` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/terraref-datasets/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_6 = pd.read_csv('../data/processed/pheno-table_populated_traits_2019-11-18T071126.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join `avg_canopy_heights` df with main df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate average canopy heights\n",
    "1. Convert df to sqlite db\n",
    "2. Group by range and column values (to bypass the current E and W plots which are still in the dataset) and date \n",
    "3. Generate average canopy height values to add to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Establish connection to sqlite db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('season_4_phenos.sqlite')\n",
    "cursor = conn.cursor()\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert df to sqlite db and generate average canopy height df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if or try here \n",
    "\n",
    "# df_6.to_sql('season_4_phenos.sqlite', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_canopy_heights = pd.read_sql_query(\"\"\"\n",
    "                                        Select range, column, date, avg(canopy_height) AS avg_canopy_height\n",
    "                                        FROM 'season_4_phenos.sqlite'\n",
    "                                        WHERE canopy_height NOTNULL\n",
    "                                        GROUP BY range, column, date\n",
    "                                        ORDER BY date DESC;\n",
    "                                        \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_7 = pd.merge(left=df_6, right=avg_canopy_heights, how='outer', on=['date', 'column', 'range']).set_index(df_6.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine other values found in E & W sites\n",
    "* entity is not a value that can be averaged, but when the duplicates are dropped, the entries with entity can get priority\n",
    "* leaf temperature\n",
    "* canopy cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_leaf_temps = pd.read_sql_query(\"\"\"\n",
    "                                        Select range, column, date, avg(leaf_temperature) AS avg_leaf_temp\n",
    "                                        FROM 'season_4_phenos.sqlite'\n",
    "                                        WHERE leaf_temperature IS NOT NULL\n",
    "                                        GROUP BY range, column, date\n",
    "                                        ORDER BY date DESC;\n",
    "                                        \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_canopy_cover = pd.read_sql_query(\"\"\"\n",
    "                                        Select range, column, date, avg(canopy_cover) AS avg_canopy_cover\n",
    "                                        FROM 'season_4_phenos.sqlite'\n",
    "                                        WHERE canopy_cover IS NOT NULL\n",
    "                                        GROUP BY range, column, date\n",
    "                                        ORDER BY date DESC;\n",
    "                                        \"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = pd.merge(left=df_7, right=average_leaf_temps, how='outer', on=['date', 'column', 'range']).set_index(df_7.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9 = pd.merge(left=df_8, right=average_canopy_cover, how='outer', on=['date', 'column', 'range']).set_index(df_8.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add temperatures to calculate GDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add growing degree days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tutorials\n",
    "\n",
    "#   mutate(date = as.Date(time), \n",
    "#          air_temp_converted = air_temperature - 273.15) %>% \n",
    "#   group_by(date) %>% \n",
    "#   summarise(min_temp = min(air_temp_converted), \n",
    "#             max_temp = max(air_temp_converted), \n",
    "#             gdd = ifelse(sum(min_temp, max_temp) / 2 > 10, \n",
    "#                          (max_temp + min_temp) / 2 - 10, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add max canopy height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-order column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add planting date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update df_* with timestamp\n",
    "# df_6 will be renamed\n",
    "\n",
    "timestamp = datetime.datetime.now().replace(microsecond=0).isoformat()\n",
    "output_filename = f'pheno-table_{timestamp}.csv'.replace(':', '')\n",
    "df_9.to_csv(f'../data/processed/{output_filename}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
